{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAEXNPz1EPOK",
        "outputId": "3b0bb852-5e4d-4cad-edb8-cd4a69d7a1a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values for each column:\n",
            "PERSONID    0\n",
            "271.0       0\n",
            "276.51      0\n",
            "283.9       0\n",
            "401.9       0\n",
            "           ..\n",
            "Z99.2       0\n",
            "Z99.3       0\n",
            "Z99.81      0\n",
            "Z99.89      0\n",
            "POMPE       0\n",
            "Length: 7509, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_parquet('/content/sample_data/diagnosis.parquet')\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display the count of missing values for each column\n",
        "print(\"Missing values for each column:\")\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of samples in each class\n",
        "class_counts = df[\"POMPE\"].value_counts()\n",
        "print(\"\\nNumber of samples in each class:\")\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wwWDW1QF-0a",
        "outputId": "d0ac6ae7-58ed-4c2b-88f1-314a78d393c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples in each class:\n",
            "0    89372\n",
            "1        7\n",
            "Name: POMPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaNs and print the indices before dropping them\n",
        "nan_indices = df[df.isna().any(axis=1)].index\n",
        "print(f\"Indices with NaN: {nan_indices.tolist()}\")\n",
        "\n",
        "# Drop the rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Confirm the removal\n",
        "print(f\"Number of rows after removing NaNs: {df.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBFIpuATGIIp",
        "outputId": "390d9677-3e84-4dd0-da7b-3042fcfd5355"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices with NaN: []\n",
            "Number of rows after removing NaNs: 89379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Time' is not a feature and 'Class' is the label\n",
        "X = df.drop(['POMPE'], axis=1)\n",
        "y = df['POMPE']\n",
        "\n",
        "# Isolation Forest for anomaly detection\n",
        "iso_forest = IsolationForest(n_estimators=300, contamination= 'auto', random_state=42)\n",
        "preds = iso_forest.fit_predict(X)\n",
        "\n",
        "# Isolation Forest marks anomalies as -1, so we convert these to 1 for our 'Class' label (assuming 1 indicates the minority class)\n",
        "anomaly_labels = pd.Series(preds).apply(lambda x: 1 if x == -1 else 0)\n",
        "\n",
        "# Evaluation\n",
        "print(classification_report(y, anomaly_labels))\n",
        "print(confusion_matrix(y, anomaly_labels))"
      ],
      "metadata": {
        "id": "XSHUMLvaGILQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5XfJYD4GIOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}